# -*- coding: utf-8 -*-
"""Data_prepration_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ByduO5ix0PTU8TTiNi8nxe9eVwRGu0Fc

This code contains pre-processing steps done on [CelebA dataset](https://www.kaggle.com/jessicali9530/celeba-dataset) from Kaggle to prepare for multi-class facial attribute classification model.

## Boiler Plate
"""

# Commented out IPython magic to ensure Python compatibility.
# %reload_ext autoreload
# %autoreload 2
# %matplotlib inline

import pandas as pd
import numpy as np
import imutils
import glob
import cv2
import shutil
from tqdm import tqdm_notebook
import matplotlib.pyplot as plt
pd.set_option('display.max_columns', 500)
tqdm_notebook().pandas()

import os
import shutil
# shutil.copy("./kaggle.json", "/root/.kaggle")
cwd = os.getcwd()
os.environ['KAGGLE_USERNAME'] = "vakninmaor"
os.environ['KAGGLE_KEY'] = "67d7e0b69a3ef47a420c5e639507c0dc"

"""## Downloading databse

We are going to download [CelebFaces Attributes(CelebA) dataset](https://www.kaggle.com/jessicali9530/celeba-dataset) from Kaggle. This dataset is excellent for training and testing models for face detection, particularly for recognizing facial attributes such as finding people with brown hair, are smiling, or wearing glasses. Images cover large pose variations, background clutter, diverse people, supported by a large number of images and rich annotations. This data was originally collected by researchers at MMLAB, The Chinese University of Hong Kong (specific reference in Acknowledgment section).

**Content**

- 202,599 number of face images of various celebrities
- 10,177 unique identities, but names of identities are not given
- 40 binary attribute annotations per image
- 5 landmark locations

We are going to use kaggle-cli to download data.
"""

!kaggle datasets download -d jessicali9530/celeba-dataset

[ f for f in os.listdir( os.curdir ) if os.path.isfile(f) ]

from zipfile import ZipFile
zf = ZipFile('celeba-dataset.zip', 'r')
zf.extractall()
zf.close()

zf1 = ZipFile('img_align_celeba.zip', 'r')
zf1.extractall()
zf1.close()

[ f for f in os.listdir( os.curdir ) if os.path.isfile(f) ]

os.listdir( os.curdir )

os.rename('img_align_celeba', 'dataset')

"""## Extracting frontal face from images

CelebA dataset contains images of faces which are taken from the side and with different orientation and zoom angle. The first step of preprocessing is you select images which in which front face is visible and isolate that part of the image alone for our model training of facial attributes. We are going to use OpenCV Haar Cascades to find the location of the face in the image and crop to only keep the facial parts of the image.
"""

import urllib.request
urllib.request.urlretrieve('https://github.com/opencv/opencv/tree/master/data/haarcascades/haarcascade_frontalface_default.xml', 'haarcascade_frontalface_default.xml')

## Loading Haar Cascade
## Taken from https://github.com/opencv/opencv/tree/master/data/haarcascades
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + "haarcascade_frontalface_default.xml")

def face_extractor(origin, destination, fc):
    ## Importing image using open cv
    img = cv2.imread(origin,1)

    ## Resizing to constant width
    img = imutils.resize(img, width=200)
    
    ## Finding actual size of image
    H,W,_ = img.shape
    
    ## Converting BGR to RGB
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    
    ## Detecting faces on the image
    face_coord = fc.detectMultiScale(gray,1.2,10,minSize=(50,50))
    
    ## If only one face is foung
    if len(face_coord) == 1:
        X, Y, w, h = face_coord[0]
    
    ## If no face found --> SKIP
    elif len(face_coord)==0:
        return None
    
    ## If multiple faces are found take the one with largest area
    else:
        max_val = 0
        max_idx = 0
        for idx in range(len(face_coord)):
            _, _, w_i, h_i = face_coord[idx]
            if w_i*h_i > max_val:
                max_idx = idx
                max_val = w_i*h_i
            else:
                pass
            
            X, Y, w, h = face_coord[max_idx]
    
    ## Crop and export the image
    img_cp = img[
            max(0,Y - int(0.35*h)): min(Y + int(1.35*h), H),
            max(0,X - int(w*0.35)): min(X + int(1.35*w), W)
        ].copy()
    
    cv2.imwrite(destination, img_cp)

## Defining destination path
path = 'faces/'

## Finding all the images in the folder
item_list = glob.glob('dataset/*.jpg')
print(len(item_list))

## Will run for about an hour and a half 
for org in tqdm_notebook(item_list):
    face_extractor(origin = org, destination = path+org.split('\\')[-1], fc=face_cascade)



## Findign all the images and separating in training and validation
item_list = glob.glob(path+'*.jpg')

for idx in tqdm_notebook(range(1,202600)):
    if idx <= 182637:
        destination = path+'training/'
    else:
        destination = path+'validation/'
    try:
        shutil.copy(
            path+str(idx).zfill(6)+'.jpg', 
            destination+str(idx).zfill(6)+'.jpg'
        )
    except:
        pass

path

"""## Label Creation"""

## Combining all label attributes
label_df = pd.read_csv('list_attr_celeba.csv')
column_list = pd.Series(list(label_df.columns)[1:])

def label_generator(row):
    return(' '.join(column_list[[True if i==1 else False for i in row[column_list]]]))

label_df['label'] = label_df.progress_apply(lambda x: label_generator(x), axis=1)
label_df = label_df.loc[:,['image_id','label']]
label_df.to_csv('labels.csv')

## Attachhing label to correct file names
item_list = glob.glob(path+'*.jpg')
item_df = pd.DataFrame({'image_name':pd.Series(item_list).apply(lambda x: x.split('\\')[-1])})
item_df['image_id'] = item_df.image_name.apply(lambda x: x)
## Creating final label set
label_df = pd.read_csv('labels.csv')
label_df = label_df.merge(item_df, on='image_id', how='inner')
label_df.rename(columns={'label':'tags'}, inplace=True)

label_df['image_id'] = item_df.image_name.apply(lambda x: int(x.split('.')[0]))

label_df.to_csv('labels.csv')

import os

# define the name of the directory to be created
path = "faces"

try:
    os.mkdir(path)
except OSError:
    print ("Creation of the directory %s failed" % path)
else:
    print ("Successfully created the directory %s " % path)

# define the name of the directory to be created
path = "faces/train"

try:
    os.mkdir(path)
except OSError:
    print ("Creation of the directory %s failed" % path)
else:
    print ("Successfully created the directory %s " % path)

# define the name of the directory to be created
path = "faces/validation"

try:
    os.mkdir(path)
except OSError:
    print ("Creation of the directory %s failed" % path)
else:
    print ("Successfully created the directory %s " % path)

label_df['train_or_validation'] = np.where(label_df['image_id']< 182638, 'train', 'validation')
# label_df['train_or_validation'].iloc[[range(182638)]] = 'train'
label_df.loc[:,['image_name','tags']].to_csv('faces/labels.csv', index=False)

label_df1 = pd.read_csv('labels.csv')
label_df1['image_id'] = label_df['train_or_validation'] + '\\' + label_df['image_name']
label_df1 = label_df1.loc[:, ~label_df1.columns.str.contains('^Unnamed')]

label_df1.to_csv('faces//labels1.csv')

label_df

'faces\\001164.jpg'.apply(lambda x: '/'.join(x.split('\\')[-1])).split('/')[1]

'/'.join('faces\\001164.jpg'.split('\\')[-1]).split('/')[1]

import torch
torch.rand(1).cuda()







